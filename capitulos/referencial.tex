\chapter{Referencial Teórico}
\label{ref}
\section{Software Analytics}
\label{ref:sof}
Durante muito tempo a disponibilidade de dados em projetos de software para análise foi um problema. Hoje em dia, com o auxílio da internet, dos projetos de software livre e das características pervasivas e ubíquas da computação, o volume de dados a serem analisados se tornou um problema. Processar e analisar esses dados manualmente se tornou inviável\cite{artAndScience}. Atualmente, por exemplo, pesquisas mostraram que o \textit{Mozilla Firefox} teve 1.3 milhões de relatos de defeitos e outras plataformas como \textit{Sourcefoge.net} e o \textit{Github} hospedam 430.000 e 38 milhões de projetos, respectivamente\cite{informationNeeds}.

Na literatura não existe um consenso da definição de \textit{Software Analytics}, o livro~\cite{artAndScience} por exemplo,  define \textit{Software Analytics} como: "A análise de dados de software para gerentes e engenheiros de software, com o objetivo de capacitar indivíduos e times de desenvolvimento, a ganhar e difundir conhecimento a partir de seus dados para tomar melhores decisões". Essa atividade de análise ajuda a usuários, desenvolvedores e gerentes a responderem questões de introspecção, por exemplo, 'O por que e como um determinado evento ocorreu'. A utilização de \textit{Software Analytics} permite esse tipo de introspecção pois ao invés de propor e considerar a análise de métricas e dados independentemente, ela propõe diferentes tipos de análise em diferentes camadas de documentos, de forma a filtrar, resumir, modelar e realizar experimentações que permitam um melhor entendimento do que está acontecendo dentro do projeto\cite{informationNeeds}.

Hoje é comum empresas como Google, Facebook e Microsoft aplicarem métodos de análise de dados diariamente em seus projetos e produtos. Além disso, o número de conferências interessadas nos assuntos de mineração e análise de artefatos de software cresceu, destacando-se duas, a\textit{Mining Software Repositories} (MSR) e a \textit{PROMISE Conference on Repeatable Experimentes in Software Engineering}. Cada uma possui um foco diferente, sendo a MSR preocupada com a coleta dos dados, enquanto que a PROMISE com a eficácia e repetibilidade da análise de dados.

\subsection{Projetos \textit{Open Source} e Software Analytics}

A análise de dados obtidos de ferramentas de versionamento de código, como o Git, Bazaar, Subversion ou CVS pode trazer informações importantes a respeito da evolução de um projeto de software, por exemplo: o nível de engajamento dos desenvolvedores; o número de defeitos; a qualidade interna do produto; resultados de execução de testes, entre outros\cite{artAndScience}. O Github, uma das ferramentas mais utilizadas de versionamento de código-fonte atualmente, fornece uma API que permite a extração de dois tipos de dados:

\begin{itemize}
    \item \textbf{Metadados:} Os metadados fornecidos são informações associadas a cada \textit{commit} ou \textit{issue}, são: criador(a), data, mensagem do \textit{commit} ou \textit{issue}, a \textit{branch}, o repositório, e o escopo do \textit{commit} ou \textit{issue}. Além disso, na mensagem do \textit{commit} podem haver referencias a outros desenvolvedores, defeitos ou outros \textit{commits} e \textit{issues}.
    \item \textbf{Snapshots:} O código fonte do projeto, que pode ser obtido em diferentes fases do desenvolvimento, já que a ferramente permite que um usuário avance ou retroceda dentro dos \textit{commits}. Desta forma, é possível analisar o código de um projeto referente em vários períodos diferentes.
\end{itemize}

Abaixo, na figura~\ref{fig:github_api}, podemos ver o digrama de classes da API fornecida pelo Github, com base nesta imagem, é possível ver que as \textit{issues} e informações dos \textit{commiters} são exportadas a partir de um ponto comum de acesso.

\newpage
\begin{figure}[!h]
    \centering
        \includegraphics[width=\textwidth,height=\textheight,keepaspectratio=true]{figuras/gtschema.eps}
    \caption{Diagrama do Esquema do Github}
    \label{fig:github_api}
\end{figure}

\section{Desenvolvimento Ágil em Projetos \textit{Open Source}}
\label{red:des}

\subsection{Scrum}
O Scrum é um \textit{framework} para o desenvolvimento e manutenção de produtos usado desde o incio dos anos 90 que possui a característica de permitir que vários processos e técnicas possam ser empregadas juntamente a ele. Os três valores essenciais do Scrum são:

\begin{itemize}
    \item Leveza.
    \item Simples de entender.
    \item Difícil de dominar.
\end{itemize}

O Scrum é fundamentado nas teorias empíricas de controle de processo, ou seja, utiliza o conhecimento vindo de experiencias e das decisões passadas. Por isto, este  \textit{framework} emprega uma abordagem iterativa e incremental para permitir aperfeiçoar a previsibilidade e os riscos. No Scrum, cada componente é essencial para o sucesso, por isso existem regras especificas para os times, artefatos e papéis dentro do \textit{framework}~\cite{scrum}.

\subsubsection{Práticas do Scrum}
\label{est:sof:met:pra}

O Scrum define algumas práticas que são aplicadas durante o desenvolvimento com o objetivo de minimizar a necessidade de reuniões. Estas práticas podem ser eventos com uma duração definida e buscam aumentar as interações entre as pessoas. A lista abaixo apresenta esses eventos e suas respectivas descrições~\cite{scrum}.

\begin{itemize}
    \item \textbf{Sprint:} Um intervalo de tempo em que são desenvolvidos os itens propostos. Este intervalo geralmente é de duas a quatro semanas e ao final de cada \textit{sprint}, um incremento de software é entregue.
    \item \textbf{Sprint Review:} Ao final de cada \textit{sprint} o time revisa as atividades realizadas durante o período em que a \textit{sprint} ocorreu. São levantados pontos de melhoria e quais foram os pontos fortes do time.
    \item \textbf{Sprint Planning:} No inicio de cada \textit{sprint}, é feita uma reunião em que são priorizadas as atividades que serão realizadas.
    \item \textbf{Product Backlog:} Conjunto de itens que serão desenvolvidos no projeto. A cada \textit{sprint} um conjunto de itens são escolhidos, retirados do \textit{Product Backlog} e implementados.
\end{itemize}

\subsection{\textit{Extremme Programming}}

O \textit{Extremme Programming}, ou XP, é um dos vários processos ágeis para desenvolvimento de \textit{software} existentes. O primeiro 



\section{Centralidade de Redes e o Ranqueamento de Páginas}
\label{ref:ran}

\subsection{Centralidade}
\label{ref:ran:cen}
Centralidade é um dos tópicos mais estudados na teoria dos grafos, sendo um tópico de grande importância em estudos de redes sociais~\cite{networks}. Ela determina o grau de importância de um vértice dentre todos os outros dentro de uma rede. Na figura \ref{fig:centrality} é ilustrado um exemplo de centralidade. O conceito de centralidade de redes já foi aplicado a diversos contextos, dentre eles: investigar a influencia de redes inter organizacionais, estudos de relevância, vantagens em redes de troca, competência em organizações formais, oportunidades de emprego e diversos outros campos do mercado e ciência\cite{centrality}.

\begin{figure}[!h]
    \centering
        \includegraphics[keepaspectratio=true,scale=0.5]{figuras/centrality.eps}
    \caption{Exemplo de Relevância de um Nó em uma Rede, extraída de \cite{muppidi}.}
    \label{fig:centrality}
\end{figure}

Diversos processos comumente encontrados no dia-a-dia são caracterizados como um processo de fluxo, como por exemplo o envio de e-mails, uma rede social acessada por milhares de usuários e a distribuição de dinheiro e informação entre pessoas. Esses processos diferem em dimensão e tipo, mas ainda assim podem ser comparados e exemplificados. Considerando que os processos de troca de e-mails, troca de informações, uma doença infecciosa que está sendo transmitida em uma população, a distribuição de pacotes e a troca de moedas representam um fluxo, então podemos descrevê-los sob a perspectiva da Teoria dos Grafos\cite{ceflow}. Por exemplo:

\begin{itemize}
\item Dinheiro: Considere uma moeda, ou nota de um dólar, que se move pela economia e muda de mãos a cada transação. Uma nota é indivisível e só pode estar em um lugar em um determinado período de tempo. Na perspectiva da teoria dos grafos, a movimentação de uma nota em uma rede pode ser feita como um \textit{passeio (Walk)}, sendo, desta forma, representado como um processo de Markov~\cite{ceflow}.
\item Fofoca: Imagine uma informação privada que passa por uma rede de empregados de uma empresa. Diferentemente de uma moeda, essa mesma informação pode estar em diversos locais diferentes em um determinado período de tempo, se replicando a cada pessoa que passa a ter acesso a informação, mas geralmente não atravessa o mesmo vértice mais de uma vez, apesar de poder visitar o mesmo nó mais de uma vez. A movimentação desta informação em grafo pode ser representada como uma trilha\footnote{Em um grafo, uma trilha(\textit{trail}) é um passeio (\textit{Walk}) que não possui arestas repetidas}~\cite{ceflow}.
\item E-mail: Um vírus, ou spam de e-mail, que envia mensagens a todos os contatos de uma pessoa simultaneamente pode ser considerado um processo de fluxo. Um e-mail pode ser representado como uma trilha da mesma forma que é realizado com uma informação, já que compartilha propriedades semelhantes, como existir em diversos locais ao mesmo tempo, e geralmente, os e-mails não passam pelo mesmo vértice, ou caminho, duas vezes~\cite{ceflow}.
\item Infecções: O caso de uma infecção em que o hospedeiro ficou imune. A infecção vai passar por duplicação de pessoa a pessoa, mas nunca vai voltar a infectar aqueles que já se tornaram imunes~\cite{ceflow}.
\item Pacotes: Um pacote de rede tem a característica de possuir um remetente e um destinatário. Normalmente é preferível que o pacote percorra o menor caminho possível até chegar ao seu destino. Dessa forma, a movimentação do pacote deve seguir o caminho geodésico\footnote{Um caminho geodésico em um grafo é composto pelas arestas que representam o menor caminho entre dois vértices.} pela rede de roteadores~\cite{ceflow}. 
\end{itemize}

A partir destas ideias discutidas a respeito de centralidade, pretende-se modelar as \textit{issues} de um repositório de código como um processo de fluxo. Uma \textit{issue} em repositório é uma informação única que pode ser associada a outras \textit{issues}, pessoas ou trechos específicos de código. Sendo assim, as informações contidas em \textit{issue} se mantem a mesma, porém com a característica de poder influenciar o planejamento e o desenvolvimento do projeto.

Ao longo dos anos, diferentes métodos de medida de centralidade foram criados, entre eles: Centralidade de Grau, Proximidade \textit{(Closeness)}, Intermediação \textit{(Betweenness)}, Autovetor \textit{(Eigen Vector)}, Informação, Intermediação de Fluxo, \textit{Rush Index}, Medidas de Influencia de Katz, Hubbell, Hoede e Taylor~\cite{centrality}. Estes métodos diferem nas suposições iniciais que fazem para alcançar o objetivo de determinar o nó com maior importância, por exemplo, o algoritmo de Freeman de proximidade e intermediação conta apenas os caminhos geodésicos entre os nós, assumindo que qualquer fluxo que percorra uma rede, siga sempre pelo caminho mais curto. Outros algoritmos como a centralidade de autovetor de Bonacich conta travessias, o que assume que as trajetórias podem ser sinuosas, atravessando nós e arestas repetidas vezes até chegar ao destino~\cite{Bonacich87}.

A partir de todos estes métodos discutidos por~\cite{ceflow},~\cite{centrality} e~\cite{Bonacich87}, foi escolhido um algoritmo para ser aplicado no exemplo de uso realizado nesta primeira etapa da monografia. O algoritmo escolhido foi o \textit{Page Ranking}, ou algoritmo de ranqueamento de paginas, a escolha deste algoritmo deu-se ao fato de ser um dos algoritmos mais utilizados no calculo de relevância e ser largamente estudado \cite{brin}, o que inclui pesquisas como a realizada por \cite{muppidi} que realiza uma comparação entre os algoritmos de ranqueamento contemporâneos. A próxima seção deste capitulo apresenta a fundamentação teórica a respeito do algoritmo de ranqueamento de páginas

\subsection{Ranqueamento de Páginas}
\label{ref:ran:pag}
O algoritmo de ranqueamento de páginas foi criado por Larry Page e Sergey em 1996. Ele permite calcular a importância relativa de páginas da web e tem aplicações em mecanismos de busca, estimativas de trafego e navegação na web. O algoritmo foi criado com o intuito de prover uma solução de busca de informações na web a partir da estrutura dos links, usada no hipertexto da web. \cite{pageRank}.

A premissa do algoritmo de ranqueamento de páginas é que cada página na web possui um número de \textit{links} de saída e de entrada, e que páginas com um grande número de \textit{links} são mais importantes do que as com poucos \textit{links}. Além disso, o algoritmo também leva em consideração a relevância dos \textit{links} de entrada de uma página, ou seja, se uma página da web possui um \textit{link} de entrada que possui uma alta relevância, essa página tende a ser mais importante que outra que possua vários \textit{links} mas que vieram de páginas menos relevantes.

A função de ranqueamento de páginas é uma função recursiva definida na seguinte forma:

Seja $x$ uma página da web. Então:
\begin{itemize}
    \item $PR(x)$ \textit{Page rank} da página  $x$
    \item $PR(y)$ \textit{Page rank} da página  $y$
    \item $L(x)$ é o conjunto de páginas que possuem link para $x$
    \item $C(y)$ é o grau de saída de $y$
    \item $\alpha$ é a probabilidade de um pulo aleatório
    \item $N$ é o número total de web-sites
\end{itemize}
\[\displaystyle PR(x) := \alpha \left ( \frac{1}{N} \right ) + (1-\alpha) \sum_{y\in L(x)} \frac{PR(y)}{C(y)}\]

A função de ranqueamento de páginas não ranqueia um \textit{web-site} por completo, mas páginas individuais de cada \textit{web-site}. O \textit{page rank} de uma página $y$ que possui \textit{links} para $x$ também não influencia o \textit{page rank} de $x$ uniformemente. No algoritmo de ranqueamento de páginas o \textit{page rank} de uma página $y$ é balanceado com base no grau de saída~\footnote{O grau de saída de um vértice em um grafo direcionado é igual ao número de caudas (\textit{tails}) incidentes ao vértice.} $C(y)$ na página $y$, de forma que quanto maior o número de \textit{links} de saída da página $y$ menos a página $x$ vai se beneficiar disto. Depois deste passo, é realizado o somatório do \textit{page rank} das páginas $y$, desta forma, cada link de entrada para a página $x$ aumenta seu \textit{page rank}~\cite{pageRank}.

Depois deste primeiro passo, a soma do \textit{page rank} $PR(y)$ é multiplicada por um fator de amortecimento $\alpha$. Este fator representa a probabilidade de um pulo aleatório em uma determinada página, ou seja, a probabilidade de que uma pessoa que esteja surfando na \textit{web}, e esteja em uma pagina $y$ clique em qualquer um dos \textit{links} desta página. A probabilidade de que uma pessoa clique em um dos \textit{links} de uma página é puramente baseada no número de \textit{links} da página, e a probabilidade que ela chegue em uma página específica é a soma das probabilidades de cada \textit{link} que a pessoa teve que seguir para chegar a ela. Por se tratar de uma probabilidade, o $\alpha$ assume valores entre 0 e 1, porém para muitos casos é sugerido o uso de 0.85~\cite{pageRank}. 

Na figura~\ref{fig:page_rank} é apresentado um exemplo como a relevância de uma página influencia as páginas seguintes.

\begin{figure}[!h]
    \centering
        \includegraphics[keepaspectratio=true,scale=0.5]{figuras/page_rank.eps}
    \caption{Simplificação do Cálculo de Ranqueamento de Páginas, extraída de \cite{pageRank}.}
    \label{fig:page_rank}
\end{figure}

\begin{figure}[!h]
    \centering
        \includegraphics[keepaspectratio=true,scale=0.5]{figuras/page_rank2.eps}
    \caption{Simplificação do Cálculo de Ranqueamento de Páginas, extraída de \cite{pageRank}.}
    \label{fig:page_rank2}
\end{figure}

A figura~\ref{fig:page_rank} ilustra como o ranqueamento de páginas se divide através das paginas e como ele contribui para o ranque das páginas seguintes. Na figura~\ref{fig:page_rank} é possível ver como uma página que possui um \textit{page rank} acumulado de 100 distribui seu ranque igualmente para as paginas seguintes, de forma que cada um dos seus dois \textit{links} receba 50 de ranque. Já em umá página que possui 9 de ranque acumulado, distribui igualmente 3 de ranque para cada um dos seus 3 \textit{links} subsequentes. Na figura~\ref{fig:page_rank2} é ilustrado como um estado estável pode ser alcançado depois que o algoritmo é executado em um conjunto de páginas, de forma que o ranque de uma página seja distribuído igualmente para as páginas posteriores a ela. 

\begin{figure}[!h]
    \centering
        \includegraphics[keepaspectratio=true,scale=0.5]{figuras/page_rank3.eps}
    \caption{\textit{Loop} de Ranqueamento, extraída de \cite{pageRank}.}
    \label{fig:page_rank3}
\end{figure}

Um dos problemas dessa função de ranqueamento, é que caso duas páginas da web que apontem uma para outra, e uma terceira aponte para qualquer uma destas, o \textit{loop} vai acumular ranque porém, nunca vai distribuir isso para nenhuma outra página seguinte. Na ilustração apresentada na figura~\ref{fig:page_rank3}, possível observar esse fenômeno.

\section{Considerações Finais do Capitulo}
Neste capitulo foi apresentado o referencial teórico a respeito dos tópicos de \textit{Software Analytics}, Centralidade e o algoritmo \textit{Page Ranking}. No próximo capitulo será apresentado como estas técnicas foram utilizadas para que fosse possível executar o exemplo de uso que faz parte desta monografia e alguns resultados colhidos a partir deste exemplo.
